## The Future of Large NN Models

Patiently waiting for the big guy to come up with GPT-8 with 75 trillion parameters and calling their API is not very productive,
and prompt-level engineering shouldn't be the go-to solution for every problem, at least not for me.
We will see more low-level pitfalls of current model architecture and we will find ways to overcome them.

Remember how I stated that Neural Networks are just a way of exaggerating parameterization problems?
I believe more and more focus will likely be put on **distillation** of such "knowledge".
